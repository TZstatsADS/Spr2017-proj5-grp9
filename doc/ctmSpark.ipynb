{"cells":[{"cell_type":"code","source":["# Replace with your values\n#\n# NOTE: Set the access to this notebook appropriately to protect the security of your keys.\n# Or you can delete this cell after you run the mount command below once successfully.\nACCESS_KEY = \"Your-access-key\"\nSECRET_KEY = \"Your-secret-key\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"ads-proj5-data/\"\nMOUNT_NAME = \"data\"\n\n#dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["display(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["review_df = spark.read.json(\"/mnt/data/reviews_Kindle_Store.json\").dropDuplicates()\nItemTopics = spark.read.load(\"/mnt/data/predictions.csv\", \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true').dropDuplicates()\nuser_map = spark.read.load(\"/mnt/data/user_map.csv\", \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')\nitem_map = spark.read.load(\"/mnt/data/item_map.csv\", \n                      format='com.databricks.spark.csv', \n                      header='true', \n                      inferSchema='true')"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["ItemTopicsRDD = ItemTopics.rdd.map(lambda r: (r[0],[r[i] for i in range(1,51)]))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["ItemTopics = spark.createDataFrame(ItemTopicsRDD,['asin','topic'])"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.sql.functions import array, avg, col"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["ItemTopics = ItemTopics.groupby(\"asin\").agg(array(*[avg(col(\"topic\")[i]) for i in range(50)]).alias(\"topic\"))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["df = review_df.select(review_df.asin,review_df.overall.alias(\"rating\"),review_df.reviewerID).join(ItemTopics,\"asin\").join(item_map,\"asin\").join(user_map,\"reviewerID\")"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["df = df.select(df.user,df.item,df.rating,df.topic)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["df.cache()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["df.rdd.getNumPartitions()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["row1 = df.agg({\"user\": \"max\", \"item\":\"max\"}).collect()\nprint row1"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.sql.functions import collect_list,first\nfrom time import time\nimport numpy as np\nfrom numpy.random import rand\nfrom numpy import matrix"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["def CTM_train(Full,I,J,K,LAMBDA,max_iter=10,n_partition=6):\n    '''\n    '''\n    \n    # define update functions\n    def updateU(i,v_ind,R,V,LAMBDA):\n        '''\n        '''\n        r = v_ind.shape[0]\n        K = V.shape[1]\n    \n        A = V[v_ind,:].T.dot(V[v_ind,:]) + LAMBDA*r*np.eye(K)\n        b = V[v_ind,:].T.dot(R).T\n        \n        return (np.linalg.solve(A, b)).T\n    \n    def updateV(j,u_ind,R,U,LAMBDA,Th):\n        '''\n        '''\n        r = u_ind.shape[0]\n        K = U.shape[1]\n    \n        A = U[u_ind,:].T.dot(U[u_ind,:]) + LAMBDA*r*np.eye(K)\n        b = U[u_ind,:].T.dot(R).T + LAMBDA*r*Th.reshape([K,1])\n    \n        return (np.linalg.solve(A, b)).T\n    \n    print('pre-compute block information...')\n    Full = Full.repartition(n_partition)\n    U_map = Full.groupBy(\"user\").agg(collect_list(\"item\").alias('items'),collect_list(\"rating\").alias('ratings')).sort('user')\n    V_map = Full.groupBy(\"item\").agg(collect_list(\"user\").alias('users'),collect_list(\"rating\").alias('ratings'), first('topic').alias('topic')).sort('item')\n    U_map = U_map.repartition(n_partition)\n    V_map = V_map.repartition(n_partition)\n    \n    print('initialize parameters...')\n    U = matrix(rand(I,K))\n    V = matrix(rand(J,K))\n    \n    Us = sc.broadcast(U)\n    Vs = sc.broadcast(V)\n    \n    print('update parameters...')\n    for i in range(max_iter):\n        \n        \n        st = time()\n        U = U_map.rdd.map(lambda r: updateU(r[0],np.array(r[1]),np.array(r[2]),Vs.value,LAMBDA)).reduce(lambda a,b: np.vstack((a,b)))\n        Us = sc.broadcast(U)\n        \n        \n        V = V_map.rdd.map(lambda r: updateV(r[0],np.array(r[1]),np.array(r[2]),Us.value,LAMBDA,np.array(r[3]))).reduce(lambda a,b: np.vstack((a,b)))\n        Vs = sc.broadcast(V)\n        ed = time()\n        \n        \n        print('Finish iteration round: '+str(i)+', use time: '+str(round(ed-st,4))+'s.\\n')\n    \n    return (U,V)        "],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["U,V = CTM_train(df,1406710,430520,50,LAMBDA=0.02,max_iter=5,n_partition=200)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["index = np.array(range(U.shape[0]))\nUM = np.column_stack((index,U))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["index = np.array(range(V.shape[0]))\nVM = np.column_stack((index,V))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["UserMatrix = sc.parallelize(UM)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["ItemMatrix = sc.parallelize(VM)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["UserMatrix.saveAsTextFile(\"/mnt/data/UserMatrixAll.txt\")"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["ItemMatrix.saveAsTextFile(\"/mnt/data/ItemMatrix.txt\")"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":22}],"metadata":{"name":"CTM","notebookId":3771531303348377},"nbformat":4,"nbformat_minor":0}
