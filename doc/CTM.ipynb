{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Topic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ctm(R_dict,Theta,n_U,n_epoch=20,batch_size=50,lambda_u=0.002,lambda_v=0.2,alpha=0.002):\n",
    "    '''\n",
    "    input: R_dict, {(i,j): Rij} maps ith user and jth item to non-zero rating i,j\n",
    "           Theta, JxK matrix, jth row is a K-dim topic vector for jth item\n",
    "           n_U, number of unique users in R_dict\n",
    "           n_epoch, number of iterations\n",
    "           lambda_u, regularization parameter for U\n",
    "           lambda_v, regularization parameter for V\n",
    "           alpha, learning rate\n",
    "           \n",
    "    output: U, a IxK matrix, each row is a K-dim representation for ith user\n",
    "            V, a JxK matrix, each row is a K-dim representation for jth item\n",
    "            U_id, user ids\n",
    "            V_id, item ids\n",
    "    '''\n",
    "    n_V,K = Theta.shape # get dimension of parameters\n",
    "    U = np.random.rand(n_U,K)\n",
    "    V = Theta.copy() # initialize parameters\n",
    "    N = len(R_dict)\n",
    "    pairs = R_dict.keys()\n",
    "    \n",
    "    if N<batch_size:\n",
    "        batch_size = 1\n",
    "    \n",
    "    for t in range(n_epoch):\n",
    "        delta = 0 # change in gradient\n",
    "        to_use = sample(pairs, batch_size)\n",
    "        for i,j in to_use: \n",
    "                r = R_dict[(i,j)]\n",
    "                u,v = U[i,:],V[j,:]\n",
    "                theta = Theta[j,:]\n",
    "                \n",
    "                gu = 2*(u.dot(v.T)-r)*v+2*lambda_u*u\n",
    "                gv = 2*(v.dot(u.T)-r.T)*u+2*lambda_v*(v-theta) # calculate gradient\n",
    "                u -= alpha*gu\n",
    "                v -= alpha*gv # update parameters\n",
    "                \n",
    "                delta += (np.linalg.norm(gu)+np.linalg.norm(gv)) # calculate change in gradient\n",
    "                U[i,:] = u\n",
    "                V[j,:] = v\n",
    "        \n",
    "        if delta < 0.001:\n",
    "            break\n",
    "    return (U,V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7035805547427936"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "np.random.seed(59)\n",
    "R = np.random.randint(0,5,size=(n,n))\n",
    "R_dict = {}\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if R[i,j]!=0:\n",
    "            R_dict[(i,j)] = R[i,j]\n",
    "\n",
    "Theta = np.random.rand(n,50)\n",
    "\n",
    "U,V = ctm(R_dict,Theta,n,n_epoch=1000)\n",
    "np.sum((U.dot(V.T)-R)**2)/len(R_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 30.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# To make it converge quick we should take average topic distribution of all the books a costumer has read as his or her initial feature\n",
    "% timeit U,V = ctm(R_dict,Theta,n,n_epoch=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3,  3.9,  2.9,  1.1,  3.9],\n",
       "       [ 2.7,  5.8,  3. ,  1.7,  4.7],\n",
       "       [ 1.2,  3.8,  2.2,  1. ,  3. ],\n",
       "       [ 2.1,  2.1,  2.3,  3.5,  1.1],\n",
       "       [ 2. ,  5.2,  1.4,  2. ,  3.8]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.dot(V.T).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4, 3, 1, 0],\n",
       "       [3, 0, 3, 1, 0],\n",
       "       [1, 4, 2, 1, 3],\n",
       "       [2, 2, 2, 4, 1],\n",
       "       [2, 0, 1, 2, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef ctm_matrix(R,Theta,U_batch_size=50,V_batch_size=40,n_epoch=20,lambda_u=0.002,lambda_v=0.2,alpha=0.0002):\\n    I,J = R.shape\\n    K = Theta.shape[1] # get dimension of parameters\\n    \\n    U = np.random.rand(I,K)\\n    V = Theta.copy() # initialize parameters\\n    \\n    n_U = int(np.ceil(I/(U_batch_size*1.0)))\\n    n_V = int(np.ceil(J/(V_batch_size*1.0)))# number of batches to be iterated\\n    \\n    for t in range(n_epoch):\\n        delta = 0 # change in gradient\\n        for u_th in range(n_U):\\n            for v_th in range(n_V): # for each mini_batch, do\\n                r = R[U_batch_size*(u_th):U_batch_size*(u_th+1),V_batch_size*(v_th):V_batch_size*(v_th+1)] \\n                u = U[U_batch_size*(u_th):U_batch_size*(u_th+1),:]\\n                v = V[V_batch_size*(v_th):V_batch_size*(v_th+1),:]\\n                theta = Theta[V_batch_size*(v_th):V_batch_size*(v_th+1),:] # get sub parameters\\n                \\n                gu = 2*(u.dot(v.T)-r).dot(v)+2*lambda_u*u\\n                gv = 2*(v.dot(u.T)-r.T).dot(u)+2*lambda_v*(v-theta) # calculate gradient\\n                u -= alpha*gu\\n                v -= alpha*gv # update parameters\\n                \\n                delta += (np.linalg.norm(gu)+np.linalg.norm(gv)) # calculate change in gradient\\n                U[U_batch_size*(u_th):U_batch_size*(u_th+1),:] = u\\n                V[V_batch_size*(v_th):V_batch_size*(v_th+1),:] = v\\n        \\n        if delta < 0.001:\\n            break\\n    return (U,V)\\n\\n'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def ctm_matrix(R,Theta,U_batch_size=50,V_batch_size=40,n_epoch=20,lambda_u=0.002,lambda_v=0.2,alpha=0.0002):\n",
    "    I,J = R.shape\n",
    "    K = Theta.shape[1] # get dimension of parameters\n",
    "    \n",
    "    U = np.random.rand(I,K)\n",
    "    V = Theta.copy() # initialize parameters\n",
    "    \n",
    "    n_U = int(np.ceil(I/(U_batch_size*1.0)))\n",
    "    n_V = int(np.ceil(J/(V_batch_size*1.0)))# number of batches to be iterated\n",
    "    \n",
    "    for t in range(n_epoch):\n",
    "        delta = 0 # change in gradient\n",
    "        for u_th in range(n_U):\n",
    "            for v_th in range(n_V): # for each mini_batch, do\n",
    "                r = R[U_batch_size*(u_th):U_batch_size*(u_th+1),V_batch_size*(v_th):V_batch_size*(v_th+1)] \n",
    "                u = U[U_batch_size*(u_th):U_batch_size*(u_th+1),:]\n",
    "                v = V[V_batch_size*(v_th):V_batch_size*(v_th+1),:]\n",
    "                theta = Theta[V_batch_size*(v_th):V_batch_size*(v_th+1),:] # get sub parameters\n",
    "                \n",
    "                gu = 2*(u.dot(v.T)-r).dot(v)+2*lambda_u*u\n",
    "                gv = 2*(v.dot(u.T)-r.T).dot(u)+2*lambda_v*(v-theta) # calculate gradient\n",
    "                u -= alpha*gu\n",
    "                v -= alpha*gv # update parameters\n",
    "                \n",
    "                delta += (np.linalg.norm(gu)+np.linalg.norm(gv)) # calculate change in gradient\n",
    "                U[U_batch_size*(u_th):U_batch_size*(u_th+1),:] = u\n",
    "                V[V_batch_size*(v_th):V_batch_size*(v_th+1),:] = v\n",
    "        \n",
    "        if delta < 0.001:\n",
    "            break\n",
    "    return (U,V)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spark Version CTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init('/Users/Zoe/spark-2.1.0-bin-hadoop2.7/')\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from numpy import matrix\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, udf\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = spark.createDataFrame([[0,1,5.0],[0,3,3.0],[0,4,2.0],[1,2,1.0],[1,3,1.0],[2,4,3.0],[3,1,2.0],[3,2,5.0],[4,0,3.0],[4,2,5.0]],['user','item','rating'])\n",
    "Th = spark.createDataFrame([[0,[0.5,0.5]],[1,[0.3,0.7]],[2,[0.2,0.8]],[3,[0.7,0.3]],[4,[0.4,0.6]]],['item','topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = spark.createDataFrame([(0, 2, 4.0), (1, 0, 3.0), (2, 0, 2.0)], [\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CTM_train(R,Th,I,J,K,LAMBDA,max_iter=10,U_threads=6,V_threads=6):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    # define update functions\n",
    "    def updateU(i,v_ind,R,V,LAMBDA):\n",
    "        '''\n",
    "        '''\n",
    "        r = v_ind.shape[0]\n",
    "        K = V.shape[1]\n",
    "    \n",
    "        A = V[v_ind,:].T.dot(V[v_ind,:]) + LAMBDA*r*np.eye(K)\n",
    "        b = V[v_ind,:].T.dot(R).T\n",
    "        \n",
    "        return (np.linalg.solve(A, b)).T\n",
    "    \n",
    "    def updateV(j,u_ind,R,U,LAMBDA,Th):\n",
    "        '''\n",
    "        '''\n",
    "        r = u_ind.shape[0]\n",
    "        K = U.shape[1]\n",
    "    \n",
    "        A = U[u_ind,:].T.dot(U[u_ind,:]) + LAMBDA*r*np.eye(K)\n",
    "        b = U[u_ind,:].T.dot(R).T #+ LAMBDA*r*Th.reshape([K,1])\n",
    "    \n",
    "        return (np.linalg.solve(A, b)).T\n",
    "    \n",
    "    print('pre-compute block information...')\n",
    "    U_map = R.groupBy(\"user\").agg(collect_list(\"item\").alias('items'),collect_list(\"rating\").alias('ratings')).sort('user')\n",
    "    U_map = U_map.repartition(U_threads)\n",
    "    V_map = R.groupBy(\"item\").agg(collect_list(\"user\").alias('users'),collect_list(\"rating\").alias('ratings')).sort('item').join(Th, \"item\")\n",
    "    V_map = V_map.repartition(V_threads)\n",
    "    \n",
    "    print('initialize parameters...')\n",
    "    U = matrix(rand(I,K))\n",
    "    V = matrix(rand(J,K))\n",
    "    \n",
    "    Us = sc.broadcast(U)\n",
    "    Vs = sc.broadcast(V)\n",
    "    \n",
    "    print('update parameters...')\n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        \n",
    "        st = time()\n",
    "        U = U_map.rdd.map(lambda r: updateU(r[0],np.array(r[1]),np.array(r[2]),Vs.value,LAMBDA)).reduce(lambda a,b: np.vstack((a,b)))\n",
    "        Us = sc.broadcast(U)\n",
    "        \n",
    "        \n",
    "        V = V_map.rdd.map(lambda r: updateV(r[0],np.array(r[1]),np.array(r[2]),Us.value,LAMBDA,np.array(r[3]))).reduce(lambda a,b: np.vstack((a,b)))\n",
    "        Vs = sc.broadcast(V)\n",
    "        ed = time()\n",
    "        \n",
    "        \n",
    "        print('Finish iteration round: '+str(i)+', use time: '+str(round(ed-st,4))+'s.\\n')\n",
    "    \n",
    "    return (U,V)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-compute block information...\n",
      "initialize parameters...\n",
      "update parameters...\n",
      "Finish iteration round: 0, use time: 3.3177s.\n",
      "\n",
      "Finish iteration round: 1, use time: 0.128s.\n",
      "\n",
      "Finish iteration round: 2, use time: 0.188s.\n",
      "\n",
      "Finish iteration round: 3, use time: 0.1489s.\n",
      "\n",
      "Finish iteration round: 4, use time: 0.141s.\n",
      "\n",
      "Finish iteration round: 5, use time: 0.1298s.\n",
      "\n",
      "Finish iteration round: 6, use time: 0.1767s.\n",
      "\n",
      "Finish iteration round: 7, use time: 0.1187s.\n",
      "\n",
      "Finish iteration round: 8, use time: 0.1367s.\n",
      "\n",
      "Finish iteration round: 9, use time: 0.1191s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U1,V1 = CTM_train(R,Th,5,5,2,LAMBDA=0.02,max_iter=10,U_threads=6,V_threads=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CTM_predict(test,U,V):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    preds = test.rdd.map(lambda r: ((r[0],r[1]),U[r[0],:].dot(V[r[1],:].T)[0,0]))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = CTM_predict(test,U1,V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test,preds,N):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    se = test.rdd.map(lambda r: ((r[0],r[1]),r[2])).join(preds).map(lambda r: (r[1][0]-r[1][1])**2).reduce(lambda a,b: a+b)\n",
    "    return se/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2620496637057741"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test,preds,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
