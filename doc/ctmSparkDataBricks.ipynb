{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace with your values\n",
    "#\n",
    "# NOTE: Set the access to this notebook appropriately to protect the security of your keys.\n",
    "# Or you can delete this cell after you run the mount command below once successfully.\n",
    "ACCESS_KEY = \"Your-access-key\"\n",
    "SECRET_KEY = \"Your-secret-key\"\n",
    "ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n",
    "AWS_BUCKET_NAME = \"ads-proj5-data/\"\n",
    "MOUNT_NAME = \"data\"\n",
    "\n",
    "dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/%s\" % MOUNT_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_df = spark.read.json(\"/mnt/data/reviews_Kindle_Store.json\").dropDuplicates()\n",
    "ItemTopics = spark.read.load(\"/mnt/data/predictions.csv\", \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header='true', \n",
    "                      inferSchema='true').dropDuplicates()\n",
    "user_map = spark.read.load(\"/mnt/data/user_map.csv\", \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header='true', \n",
    "                      inferSchema='true')\n",
    "item_map = spark.read.load(\"/mnt/data/item_map.csv\", \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header='true', \n",
    "                      inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ItemTopicsRDD = ItemTopics.rdd.map(lambda r: (r[0],[r[i] for i in range(1,51)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ItemTopics = spark.createDataFrame(ItemTopicsRDD,['asin','topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array, avg, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ItemTopics = ItemTopics.groupby(\"asin\").agg(array(*[avg(col(\"topic\")[i]) for i in range(50)]).alias(\"topic\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = review_df.select(review_df.asin,review_df.overall.alias(\"rating\"),review_df.reviewerID).join(ItemTopics,\"asin\").join(item_map,\"asin\").join(user_map,\"reviewerID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.select(df.user,df.item,df.rating,df.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row1 = df.agg({\"user\": \"max\", \"item\":\"max\"}).collect()\n",
    "print row1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list,first\n",
    "from time import time\n",
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from numpy import matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CTM_train(Full,I,J,K,LAMBDA,max_iter=10,n_partition=6):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    # define update functions\n",
    "    def updateU(i,v_ind,R,V,LAMBDA):\n",
    "        '''\n",
    "        '''\n",
    "        r = v_ind.shape[0]\n",
    "        K = V.shape[1]\n",
    "    \n",
    "        A = V[v_ind,:].T.dot(V[v_ind,:]) + LAMBDA*r*np.eye(K)\n",
    "        b = V[v_ind,:].T.dot(R).T\n",
    "        \n",
    "        return (np.linalg.solve(A, b)).T\n",
    "    \n",
    "    def updateV(j,u_ind,R,U,LAMBDA,Th):\n",
    "        '''\n",
    "        '''\n",
    "        r = u_ind.shape[0]\n",
    "        K = U.shape[1]\n",
    "    \n",
    "        A = U[u_ind,:].T.dot(U[u_ind,:]) + LAMBDA*r*np.eye(K)\n",
    "        b = U[u_ind,:].T.dot(R).T + LAMBDA*r*Th.reshape([K,1])\n",
    "    \n",
    "        return (np.linalg.solve(A, b)).T\n",
    "    \n",
    "    print('pre-compute block information...')\n",
    "    Full = Full.repartition(n_partition)\n",
    "    U_map = Full.groupBy(\"user\").agg(collect_list(\"item\").alias('items'),collect_list(\"rating\").alias('ratings')).sort('user')\n",
    "    V_map = Full.groupBy(\"item\").agg(collect_list(\"user\").alias('users'),collect_list(\"rating\").alias('ratings'), first('topic').alias('topic')).sort('item')\n",
    "    U_map = U_map.repartition(n_partition)\n",
    "    V_map = V_map.repartition(n_partition)\n",
    "    \n",
    "    print('initialize parameters...')\n",
    "    U = matrix(rand(I,K))\n",
    "    V = matrix(rand(J,K))\n",
    "    \n",
    "    Us = sc.broadcast(U)\n",
    "    Vs = sc.broadcast(V)\n",
    "    \n",
    "    print('update parameters...')\n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        \n",
    "        st = time()\n",
    "        U = U_map.rdd.map(lambda r: updateU(r[0],np.array(r[1]),np.array(r[2]),Vs.value,LAMBDA)).reduce(lambda a,b: np.vstack((a,b)))\n",
    "        Us = sc.broadcast(U)\n",
    "        \n",
    "        \n",
    "        V = V_map.rdd.map(lambda r: updateV(r[0],np.array(r[1]),np.array(r[2]),Us.value,LAMBDA,np.array(r[3]))).reduce(lambda a,b: np.vstack((a,b)))\n",
    "        Vs = sc.broadcast(V)\n",
    "        ed = time()\n",
    "        \n",
    "        \n",
    "        print('Finish iteration round: '+str(i)+', use time: '+str(round(ed-st,4))+'s.\\n')\n",
    "    \n",
    "    return (U,V)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U,V = CTM_train(df,1406710,430520,50,LAMBDA=0.01,max_iter=5,n_partition=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexU = np.array(range(U.shape[0]))\n",
    "UM = np.column_stack((indexU,U))\n",
    "indexV = np.array(range(V.shape[0]))\n",
    "VM = np.column_stack((indexV,V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UserMatrix = sc.parallelize(UM)\n",
    "ItemMatrix = sc.parallelize(VM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UsM = UserMatrix.map(lambda r: r.tolist()[0])\n",
    "VsM = ItemMatrix.map(lambda r: r.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toCSVLine(data):\n",
    "    return ','.join(str(d) for d in data)\n",
    "\n",
    "Utxt = UsM.map(toCSVLine)\n",
    "Utxt.saveAsTextFile('/mnt/data/UserTopics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vtxt = VsM.map(toCSVLine)\n",
    "Vtxt.saveAsTextFile('/mnt/data/ItemTopics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "CTM",
  "notebookId": 3771531303348377
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
